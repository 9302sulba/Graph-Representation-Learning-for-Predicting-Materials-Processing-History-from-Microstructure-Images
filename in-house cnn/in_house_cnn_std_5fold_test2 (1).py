# -*- coding: utf-8 -*-
"""in-house-CNN_std_5fold_test2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1R5nHTh8DjSzHj-0wQ5wRNHZjcbXuw16t
"""

# # Required functions for loading and processing data set

# ## Loading libraries

from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

import glob
import cv2
import numpy as np
import pandas as pd
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import os, sys, pickle, gzip, time



from tensorflow.keras.models import Sequential,Model
from tensorflow.keras.layers import BatchNormalization, Conv2D, MaxPooling2D,Activation,Dropout
from tensorflow.keras.layers import Dense,Flatten,Input,concatenate, GlobalAveragePooling2D
from tensorflow.keras.backend import sigmoid
from tensorflow.keras.utils import get_custom_objects
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint

from tensorflow.keras.applications import VGG16, imagenet_utils

from tensorflow.keras.preprocessing.image import load_img
from tensorflow.keras.preprocessing.image import img_to_array

import warnings
warnings.filterwarnings('ignore')

import tensorflow as tf


print("INFO............................")



print("python version:{}\n".format(sys.version))



print("TF version:{}\n".format(tf.__version__))



t1 = time.time()
# ## Loading images min-max

def load_image_minmax(inputPath):
    # initialize the list of column names in the CSV file and then
    # load it using Pandas
    cols = ["Cr","Co","temperature","min", "max", "image_name"]
    df = pd.read_excel(inputPath,header=None, names=cols)
    # return the data frame
    return df


# ## Processing of image min_max

def process_image_minmax(df, train, test):
    # initialize the column names of the continuous data
    continuous = ["min", "max"]
    # performin min-max scaling each continuous feature column to
    # the range [0, 1]
    cs = MinMaxScaler()
    trainContinuous = cs.fit_transform(train[continuous])
    testContinuous = cs.transform(test[continuous])
    # construct our training and testing data points by concatenating
    # the categorical features with the continuous features
    # trainX = np.hstack([trainContinuous])
    # testX = np.hstack([testContinuous])
    # return the concatenated training and testing data
    trainX = np.array(trainContinuous)
    testX = np.array(testContinuous)
    return (trainX, testX)


# ## Load Spinodal images

def load_spinodal_images(df, inputPath):
    # initialize our images array (i.e., the house images themselves)
    images = []
    # loop over the indexes of the houses
    for i in df['image_name']:
        # find the the images for the spinodal
        #imagePath = inputPath + i
        imagePath = os.path.sep.join([inputPath, str(i)])
        #imagePath = os.path.join(inputPath,str(i))
        #imagePath = os.path.join(inputPath,i)
        image = cv2.imread(imagePath)
        #print(image.shape)
        image = cv2.resize(image,(224,224))
        images.append(image)
        #image = cv2.resize(image, (32, 32))
        #images.append(image)
    # return our set of images
    return np.array(images)


# # Model development

# ## Developed convolutional layers

def create_cnn(width, height, depth, filters=(32, 64, 128), regress=False):
    # initialize the input shape and channel dimension, assuming
    # TensorFlow/channels-last ordering
    inputShape = (height, width, depth)
    chanDim = -1
    # define the model input
    inputs = Input(shape=inputShape)
    # loop over the number of filters
    for (i, f) in enumerate(filters):
        # if this is the first CONV layer then set the input
        # appropriately
        if i == 0:
            x = inputs
        # CONV => RELU => BN => POOL
        x = Conv2D(f, (3, 3), padding="same")(x)
        x = Activation("relu")(x)
        x = BatchNormalization(axis=chanDim)(x)
        x = MaxPooling2D(pool_size=(2, 2))(x)
        # flatten the volume, then FC => RELU => BN => DROPOUT
    x = Flatten()(x)
    x = Dense(16)(x)
    x = Activation("relu")(x)
    x = BatchNormalization(axis=chanDim)(x)
    x = Dropout(0.5)(x)
    # apply another FC layer, this one to match the number of nodes
    # coming out of the MLP
    x = Dense(4)(x)
    x = Activation("relu")(x)
    # check to see if the regression node should be added
    if regress:
        x = Dense(1, activation="linear")(x)
    # construct the CNN
    model = Model(inputs, x)
    # return the CNN
    return model


# ## FC for combining output of CNN with numeric data (image min_max)

from tensorflow.keras.layers import Input, Dense
from tensorflow.keras.models import Model

def create_mlp(dim, regress=False):
    inputs = Input(shape=(dim,))
    x = Dense(8, activation="relu")(inputs)
    x = Dense(4, activation="relu")(x)

    if regress:
        x = Dense(1, activation="linear")(x)

    model = Model(inputs, x)
    return model

from sklearn.metrics import r2_score, mean_squared_error
import matplotlib.pyplot as plt

def plot_loss(history, plot_name):
    plt.figure()

    # If input is a History object, get .history dict
    if hasattr(history, 'history'):
        h = history.history
    else:  # assume it's already a dict
        h = history

    plt.plot(h['loss'], label='loss')
    plt.plot(h['val_loss'], label='val_loss')
    plt.ylim([0, 100])
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(False)
    plt.title(plot_name)
    plt.savefig(plot_name, dpi=120, facecolor='w', edgecolor='w')
    plt.close()


# def parity_plot(ground_truth, prediction, lims_min, lims_max, plot_name):
#     plt.figure()
#     plt.scatter(ground_truth, prediction, label='Data')
#     #plt.plot(ground_truth, ground_truth, color='k', label='Predictions')
#     lims = [lims_min, lims_max]
#     plt.xlim(lims)
#     plt.ylim(lims)
#     _ = plt.plot(lims, lims)
#     plt.xlabel('Groud truth', fontsize=18)
#     plt.ylabel('Prediction', fontsize=18)
#     #plt.legend()
#     plt.title(plot_name)
#     plt.savefig(plot_name,dpi=120, facecolor='w', edgecolor='w')


# def parity_plot(ground_truth, prediction, lims_min, lims_max, plot_name):
#     plt.figure(figsize=(3.5, 3.5),dpi=200)
#     plt.scatter(ground_truth, prediction,color='black', s=8)
#     #plt.plot(ground_truth, ground_truth, color='k', label='Predictions')
#     lims = [lims_min, lims_max]
#     plt.xlim(lims)
#     plt.ylim(lims)
#     _ = plt.plot(lims, lims, 'k--', linewidth=1)  # 'k' = black, '--' = dashed
#     plt.xlabel('Ground truth', fontsize=20, labelpad=4)
#     plt.ylabel('Prediction', fontsize=20, labelpad=4)
#     #plt.legend()
#     plt.title(plot_name,fontsize=20,loc='center')
#     plt.tick_params(axis='both', which='both', length=0)

#     r2 = r2_score(ground_truth, prediction)
#     mse = mean_squared_error(ground_truth, prediction)
#     plt.text(
#     0.02, 0.98,
#     f'$\\bf{{R-Squared}}$ = {r2:.4f}\n$\\bf{{MSE}}$ = {mse:.1E}',
#     fontsize=12,            # bigger font
#     color='black',
#     ha='left',
#     va='top',
#     transform=plt.gca().transAxes)

#     plt.tight_layout(pad=0.5)
#     plt.savefig(plot_name,dpi=150, facecolor='w', edgecolor='w')
#     plt.close()

# def parity_plot(ground_truth, prediction, lims_min, lims_max, plot_name,metric_ground_truth=None, metric_prediction=None):
#     plt.figure(figsize=(3.5, 3.5),dpi=200)
#     plt.scatter(ground_truth, prediction,color='black', s=8)
#     #plt.plot(ground_truth, ground_truth, color='k', label='Predictions')
#     lims = [lims_min, lims_max]
#     plt.xlim(lims)
#     plt.ylim(lims)
#     _ = plt.plot(lims, lims, 'k--', linewidth=1)  # 'k' = black, '--' = dashed
#     plt.xlabel('Ground truth', fontsize=20, labelpad=4)
#     plt.ylabel('Prediction', fontsize=20, labelpad=4)
#     #plt.legend()
#     plt.title(plot_name,fontsize=20,loc='center')
#     plt.tick_params(axis='both', which='both', length=0)

# #     r2 = r2_score(ground_truth, prediction)
# #     mse = mean_squared_error(ground_truth, prediction)
#    # Use normalized values if provided
#     gt = metric_ground_truth if metric_ground_truth is not None else ground_truth
#     pred = metric_prediction if metric_prediction is not None else prediction

#     r2 = r2_score(gt, pred)
#     mse = mean_squared_error(gt, pred)
#     plt.text(
#     0.02, 0.98,
#     f'$\\bf{{R-Squared}}$ = {r2:.4f}\n$\\bf{{MSE}}$ = {mse:.1E}',
#     fontsize=12,            # bigger font
#     color='black',
#     ha='left',
#     va='top',
#     transform=plt.gca().transAxes)

#     plt.tight_layout(pad=0.5)
#     plt.savefig(plot_name,dpi=150, facecolor='w', edgecolor='w')
#     plt.close()
 # Data

# ## Data path

# from sklearn.metrics import r2_score, mean_squared_error
# import matplotlib.pyplot as plt

# def parity_plot(ground_truth_norm, prediction_norm, max_value=None,lims_min=None, lims_max=None, plot_name="parity_plot.png", label="Target",custom_ticks=False, tick_interval=20):
#     """
#     Plots a parity plot. If max_value is provided, denormalizes the axes by multiplying.
#     MSE and R² are calculated on normalized values.
#     """
#     # Denormalize for plotting (if max_value is provided)
#     if max_value is not None:
#         ground_truth_plot = ground_truth_norm * max_value
#         prediction_plot = prediction_norm * max_value
#     else:
#         ground_truth_plot = ground_truth_norm
#         prediction_plot = prediction_norm

#     # Compute metrics on normalized values
#     r2 = r2_score(ground_truth_norm, prediction_norm)
#     mse = mean_squared_error(ground_truth_norm, prediction_norm)

#     # Determine plot limits
#     if lims_min is None:
#         lims_min = ground_truth_plot.min() - 10
#     if lims_max is None:
#         lims_max = ground_truth_plot.max() + 10
#     lims = [lims_min, lims_max]

#     # Plot
#     plt.figure(figsize=(3.5, 3.5), dpi=200)
#     plt.scatter(ground_truth_plot, prediction_plot, color='black', s=5)
#     plt.plot(lims, lims, 'k--', linewidth=1)
#     plt.xlim(lims)
#     plt.ylim(lims)
#     if custom_ticks:
#         ticks = np.arange(lims_min, lims_max + 1, tick_interval)
#         plt.xticks(ticks)
#         plt.yticks(ticks)
#     plt.xlabel('Ground Truth', fontsize=25, labelpad=4)
#     plt.ylabel('Prediction', fontsize=25, labelpad=4)
#     plt.title(label,fontsize=20,loc='center')
#     plt.tick_params(axis='both', which='both', length=0)

#     # Display normalized MSE and R²
#     plt.text(
#         0.02, 0.98,
#         f'$\\bf{{R-Squared}}$ = {r2:.4f}\n$\\bf{{MSE}}$ = {mse:.1E}',
#         fontsize=14,
#         color='black',
#         ha='left',
#         va='top',
#         transform=plt.gca().transAxes
#     )

#     plt.tight_layout(pad=0.5)
#     plt.savefig(plot_name,dpi=200, facecolor='w', edgecolor='w')
#     plt.close()

path="/bsuscratch/sulbhamalviya/Amirs_code_testing/inhouse_cnn/clean_data/"
# ## Data loading

print("[INFO] loading images min-max...")
inputPath = os.path.sep.join([path, "clean_data_no_time.xlsx"])
df = load_image_minmax(inputPath)

print("Data shape")
print(df.shape)

print("[INFO] loading spinodal images...")
images = load_spinodal_images(df, path)
images = images / 255.0
print("Image shape")
print(images.shape)

# print("[INFO] processing data...")
# split = train_test_split(df, images, test_size=0.25, random_state=42)
# (trainAttrX, testAttrX, trainImagesX, testImagesX) = split

# print("[INFO] Train shape")
# print(trainAttrX.shape)
# print("[INFO] Test shape")
# print(testAttrX.shape)

# colY = ["temperature", "Cr", "Co"]


# maxTemp = trainAttrX["temperature"].max()
# print("maxTemp:", maxTemp)
# trainAttrX["temperature"] = trainAttrX["temperature"] / maxTemp
# testAttrX["temperature"] = testAttrX["temperature"] / maxTemp
# trainY = np.array(trainAttrX[colY])
# print("[INFO] Train labels shape")
# print(trainY.shape)
# testY = np.array(testAttrX[colY])
# print("[INFO] Test labels shape")
# print(testY.shape)
# (trainAttrX, testAttrX) = process_image_minmax(df,trainAttrX, testAttrX)


# # # Compile the Model

print("[INFO] processing data...")

colY = ["temperature", "Cr", "Co"]

# Keep original temperature for reference
df["temperature_orig"] = df["temperature"]

# Scale temperature for model input
maxTemp = df["temperature_orig"].max()
df["temperature_scaled"] = df["temperature_orig"] / maxTemp

print("Original max:", df["temperature_orig"].max())  # 970
print("Scaled max:", df["temperature_scaled"].max())   # 1.0

# Prepare labels array (using scaled temperature)
Y = np.array(df[["temperature_scaled", "Cr", "Co"]])

print(maxTemp)

# from tensorflow.keras.optimizers.schedules import ExponentialDecay
# from tensorflow.keras.optimizers import Adam

# # create the MLP and CNN models
# mlp = create_mlp(trainAttrX.shape[1], regress=False)
# cnn = create_cnn(224, 224, 3, regress=False)
# # create the input to our final set of layers as the *output* of both
# # the MLP and CNN
# combinedInput = concatenate([mlp.output, cnn.output])
# # our final FC layer head will have two dense layers, the final one
# # being our regression head
# x = Dense(32, activation="relu")(combinedInput)
# x = Dense(16, activation="relu")(x)
# x = Dense(3, activation="linear")(x)
# #x = Dense(4, activation="relu")(combinedInput)
# #x = Dense(3, activation="linear")(x)
# # our final model will accept categorical/numerical data on the MLP
# # input and images on the CNN input, outputting a single value (the
# # predicted temperature of the spinodal)
# model = Model(inputs=[mlp.input, cnn.input], outputs=x)
# # compile the model using mean absolute percentage error as our loss,
# # implying that we seek to minimize the absolute percentage difference
# # between our temperature *predictions* and the *actual temperatures*

# # Define learning rate schedule
# # lr_schedule = ExponentialDecay(
# #     initial_learning_rate=1e-3,
# #     decay_steps=200,
# #     decay_rate=0.5,    # halve every 200 steps (close to linear old style)
# #     staircase=True
# # )

# opt = Adam(learning_rate=1e-3)
# # Use it in optimizer
# # opt = Adam(learning_rate=lr_schedule)

# model.compile(loss="mean_absolute_percentage_error", optimizer=opt)

# cnn.summary()

# mlp.summary()

# model.summary()

# # train the model
# best_weights = 'outputs/weights_best_devCNN_.keras'
# checkpoint = ModelCheckpoint(best_weights, monitor='val_loss', verbose=1, save_best_only=True, mode='min')
# print("[INFO] training model...")
# history=model.fit(
#     x=[trainAttrX, trainImagesX], y=trainY,
#     validation_data=([testAttrX, testImagesX], testY),
#     epochs=1000, batch_size=8,callbacks=[checkpoint], verbose=0)

# # make predictions on the testing data
# print("[INFO] predicting temperatures...")
# preds = model.predict([testAttrX, testImagesX])
# #print("Actual Temperature & Cr & Co ...")
# print("Temperature accuracy ...")
# print("R-squared:")
# print(r2_score(testY[:,0], preds[:,0]))
# print("MSE:")
# print(mean_squared_error(testY[:,0], preds[:,0]))

# print("Cr accuracy ...")
# print("R-squared:")
# print(r2_score(testY[:,1], preds[:,1]))
# print("MSE:")
# print(mean_squared_error(testY[:,1], preds[:,1]))

# print("Co accuracy ...")
# print("R-squared:")
# print(r2_score(testY[:,2], preds[:,2]))
# print("MSE:")
# print(mean_squared_error(testY[:,2], preds[:,2]))

# print("[INFO] predicting temperatures with the best weights...")
# print('Test accuracy of the epoch that resulted  in the best validation accuracy_devCNN\n')
# model.load_weights(best_weights)
# opt = Adam(learning_rate=1e-3)
# model.compile(loss="mean_absolute_percentage_error", optimizer=opt)
# preds = model.predict([testAttrX, testImagesX])
# print("Temperature accuracy ...")
# print("R-squared:")
# print(r2_score(testY[:,0], preds[:,0]))
# print("MSE:")
# print(mean_squared_error(testY[:,0], preds[:,0]))

# print("Cr accuracy ...")
# print("R-squared:")
# print(r2_score(testY[:,1], preds[:,1]))
# print("MSE:")
# print(mean_squared_error(testY[:,1], preds[:,1]))

# print("Co accuracy ...")
# print("R-squared:")
# print(r2_score(testY[:,2], preds[:,2]))
# print("MSE:")
# print(mean_squared_error(testY[:,2], preds[:,2]))

# plot_loss(history,'devCNN')
# name_graph_temp = 'Temperature'
# # parity_plot(testY[:,0]*963, preds[:,0]*963, (testY[:,0]*963).min()-10 ,(testY[:,0]*963).max()+10, name_graph_temp)
# #parity_plot(testY[:,0], preds[:,0], (testY[:,0]).min()-10 ,(testY[:,0]).max()+10, name_graph_temp)
# parity_plot(testY[:,0], preds[:,0], max_value=maxTemp, plot_name="temperature_plot.png", label="Temperature",custom_ticks=True,
#     tick_interval=20)


# # gt_real = testY[:, 0] * maxTemp
# # pred_real = preds[:, 0] * maxTemp

# # # Normalized values for MSE
# # gt_norm = testY[:, 0]
# # pred_norm = preds[:, 0]

# # # Call the enhanced function
# # parity_plot(
# #     ground_truth=gt_real,
# #     prediction=pred_real,
# #     lims_min=gt_real.min() - 10,
# #     lims_max=gt_real.max() + 10,
# #     plot_name=name_graph_temp,
# #     metric_ground_truth=gt_norm,
# #     metric_prediction=pred_norm
# # )


# name_graph_cr = 'Cr'
# # parity_plot(testY[:,1], preds[:,1], 0, 1, name_graph_cr)
# parity_plot(testY[:,1], preds[:,1], lims_min=0, lims_max=1, plot_name="cr_plot.png", label="Cr")
# parity_plot(testY[:,2], preds[:,2],lims_min=0, lims_max=1, plot_name="co_plot.png", label="Co")

# name_graph_co = 'Co'
# # parity_plot(testY[:,2], preds[:,2], 0, 1, name_graph_co)
# ################################ SAVE THE MODEL HISTORY ####################################

# picklefile = 'outputs/model_history_devCNN_.pkl'
# output = open(picklefile,'wb')
# pickle.dump(history.history, output)
# output.close()
# print('pickle file written to:{}'.format(picklefile))
# print('Total time taken:{}'.format(time.time()-t1))

def parity_plot(
    ground_truth_norm, prediction_norm,
    max_value=None, lims_min=None, lims_max=None,
    plot_name="parity_plot.png", label="Target",
    custom_ticks=False, tick_interval=20,
    mse_mean=None, mse_std=None, r2_mean=None, r2_std=None
):
    import numpy as np
    import matplotlib.pyplot as plt
    from sklearn.metrics import r2_score, mean_squared_error

    # Convert to numpy
    ground_truth_norm = np.array(ground_truth_norm)
    prediction_norm = np.array(prediction_norm)

    # Denormalize if needed
    if max_value is not None:
        ground_truth_plot = ground_truth_norm * max_value
        prediction_plot = prediction_norm * max_value
    else:
        ground_truth_plot = ground_truth_norm
        prediction_plot = prediction_norm

    # Determine limits
    if lims_min is None:
        lims_min = ground_truth_plot.min() - 10
    if lims_max is None:
        lims_max = ground_truth_plot.max() + 10
    lims = [lims_min, lims_max]

    plt.figure(figsize=(3.5,3.5), dpi=200)
    plt.scatter(ground_truth_plot, prediction_plot, color='black', s=5)
    plt.plot(lims, lims, 'k--', linewidth=1)
    plt.xlim(lims)
    plt.ylim(lims)

    if custom_ticks:
        ticks = np.arange(lims_min, lims_max+1, tick_interval)
        plt.xticks(ticks)
        plt.yticks(ticks)

    plt.xlabel("Ground Truth", fontsize=25, labelpad=4)
    plt.ylabel("Prediction", fontsize=25, labelpad=4)
    plt.title(label, fontsize=20, loc="center")
    plt.tick_params(axis='both', which='both', length=0)

    # Display metrics
    if mse_mean is not None and r2_mean is not None:
        # Combined plot: show mean ± std
        plt.text(
            0.02, 0.98,
            f"MSE = {mse_mean:.4f} ± {mse_std:.4f}\nR²  = {r2_mean:.4f} ± {r2_std:.4f}",
            fontsize=14, color='black', ha='left', va='top', transform=plt.gca().transAxes
        )
    else:
        # Single-fold plot: show MSE & R²
        r2 = r2_score(ground_truth_norm, prediction_norm)
        mse = mean_squared_error(ground_truth_norm, prediction_norm)
        plt.text(
            0.02, 0.98,
            f"R² = {r2:.4f}\nMSE = {mse:.1E}",
            fontsize=14, color='black', ha='left', va='top', transform=plt.gca().transAxes
        )
    plt.tight_layout(pad=0.5)
    plt.savefig(plot_name, dpi=200)
    plt.close()

from sklearn.model_selection import KFold
from sklearn.metrics import r2_score, mean_squared_error
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
import numpy as np
import pickle, time
import os

os.makedirs("combined_outputs", exist_ok=True)
os.makedirs("eachfold_plot", exist_ok=True)

# ========== FUNCTION TO BUILD MODEL ==========
def build_model():
    mlp = create_mlp(x_attr_train.shape[1], regress=False)
    cnn = create_cnn(224, 224, 3, regress=False)

    combinedInput = concatenate([mlp.output, cnn.output])
    x = Dense(32, activation="relu")(combinedInput)
    x = Dense(16, activation="relu")(x)
    x = Dense(3, activation="linear")(x)

    model = Model(inputs=[mlp.input, cnn.input], outputs=x)
    opt = Adam(learning_rate=1e-3)
    model.compile(loss="mean_absolute_percentage_error", optimizer=opt)
    return model

# ========== SETUP ==========
kf = KFold(n_splits=5, shuffle=True, random_state=42)
fold_no = 1
val_scores = []
t1 = time.time()
all_histories = []  # <-- to store history for averaging

# To store predictions and targets across folds
all_preds_temp, all_targets_temp = [], []
all_preds_cr, all_targets_cr = [], []
all_preds_co, all_targets_co = [], []

# To store per-fold MSE and R²
mse_temp_scores, r2_temp_scores = [], []
mse_cr_scores, r2_cr_scores       = [], []
mse_co_scores, r2_co_scores       = [], []


# ========== 5-FOLD TRAINING LOOP ==========
for train_index, val_index in kf.split(df):
    print(f"\n[INFO] Starting Fold {fold_no}...")

    # Split data for this fold
    x_train_df, x_val_df = df.iloc[train_index], df.iloc[val_index]
    y_train, y_val = Y[train_index], Y[val_index]
    x_img_train, x_img_val = images[train_index], images[val_index]

    # Scale continuous columns (e.g., 'min' and 'max') inside the fold
    continuous = ["min", "max"]
    cs = MinMaxScaler()
    x_train_scaled = cs.fit_transform(x_train_df[continuous])
    x_val_scaled = cs.transform(x_val_df[continuous])

    # Convert to numpy arrays for model input
    x_attr_train = np.array(x_train_scaled)
    x_attr_val = np.array(x_val_scaled)

    # Build and compile fresh model
    model = build_model()

    # Checkpoint for best validation loss
    best_weights = f'outputs/weights_best_fold{fold_no}.keras'
    checkpoint = ModelCheckpoint(best_weights, monitor='val_loss', verbose=1, save_best_only=True, mode='min')


    print(f"[INFO] Training model for Fold {fold_no} ...")
    history = model.fit(
        x=[x_attr_train, x_img_train], y=y_train,
        validation_data=([x_attr_val, x_img_val], y_val),
        epochs=1000, batch_size=32,
        callbacks=[checkpoint], verbose=0
    )

    # Save fold history for averaging later
    all_histories.append(history.history)

    # Load best weights before validation evaluation
    model.load_weights(best_weights)

    # Predict on validation data
    preds_val = model.predict([x_attr_val, x_img_val])
    # ===== STEP 2 FOR ALL 3 TARGETS =====
# Temperature
# Inside the fold loop, for Temperature
    mse_temp = mean_squared_error(y_val[:,0], preds_val[:,0])
    r2_temp  = r2_score(y_val[:,0], preds_val[:,0])

    mse_temp_scores.append(mse_temp)   # store per fold
    r2_temp_scores.append(r2_temp)

    all_preds_temp.extend(preds_val[:,0])
    all_targets_temp.extend(y_val[:,0])

# Single-fold parity plot for temperature
    parity_plot(
        ground_truth_norm=y_val[:,0],
        prediction_norm=preds_val[:,0],
        max_value=maxTemp,  # denormalize if needed
        plot_name=f"/bsuscratch/sulbhamalviya/Amirs_code_testing/inhouse_cnn/eachfold_plot/parity_temp_fold{fold_no}.png",
        label=f"Temperature - Fold {fold_no}",
        custom_ticks=True, tick_interval=20
    )

 # ========== Cr ==========
    mse_cr = mean_squared_error(y_val[:,1], preds_val[:,1])
    r2_cr  = r2_score(y_val[:,1], preds_val[:,1])

    mse_cr_scores.append(mse_cr)       # store MSE per fold
    r2_cr_scores.append(r2_cr)

    all_preds_cr.extend(preds_val[:,1])
    all_targets_cr.extend(y_val[:,1])
# Single-fold parity plot for Cr
    parity_plot(
        ground_truth_norm=y_val[:,1],
        prediction_norm=preds_val[:,1],
        lims_min=0, lims_max=1,
        plot_name=f"/bsuscratch/sulbhamalviya/Amirs_code_testing/inhouse_cnn/eachfold_plot/parity_cr_fold{fold_no}.png",
        label=f"Cr - Fold {fold_no}"
    )
# ========== C0 ==========
    mse_co = mean_squared_error(y_val[:,2], preds_val[:,2])
    r2_co  = r2_score(y_val[:,2], preds_val[:,2])

    mse_co_scores.append(mse_co)       # store MSE per fold
    r2_co_scores.append(r2_co)

    all_preds_co.extend(preds_val[:,2])
    all_targets_co.extend(y_val[:,2])

# Single-fold parity plot for Cr
    parity_plot(
        ground_truth_norm=y_val[:,2],
        prediction_norm=preds_val[:,2],
        lims_min=0, lims_max=1,
        plot_name=f"/bsuscratch/sulbhamalviya/Amirs_code_testing/inhouse_cnn/eachfold_plot/parity_co_fold{fold_no}.png",
        label=f"Co - Fold {fold_no}"
    )

    # ========== SAVE HISTORY ==========
    picklefile = f'outputs/model_history_fold{fold_no}.pkl'
    with open(picklefile, 'wb') as f:
        pickle.dump(history.history, f)
    print(f'History saved to: {picklefile}')

    fold_no += 1

# ========== AFTER ALL FOLDS ==========
print("\n[INFO] Cross-validation complete.")

# ========== AVERAGE LEARNING CURVE ==========
num_epochs = len(all_histories[0]['loss'])
avg_history = {'loss': [], 'val_loss': []}
for epoch in range(num_epochs):
    avg_loss = np.mean([h['loss'][epoch] for h in all_histories])
    avg_val_loss = np.mean([h['val_loss'][epoch] for h in all_histories])
    avg_history['loss'].append(avg_loss)
    avg_history['val_loss'].append(avg_val_loss)

plot_loss(avg_history, 'devCNN_avgFold')  # <-- averaged learning curve

print(f'Total time taken: {time.time()-t1:.2f} seconds')

# Temperature
mse_temp_mean, mse_temp_std = np.mean(mse_temp_scores), np.std(mse_temp_scores)
r2_temp_mean, r2_temp_std   = np.mean(r2_temp_scores), np.std(r2_temp_scores)

# Cr
mse_cr_mean, mse_cr_std = np.mean(mse_cr_scores), np.std(mse_cr_scores)
r2_cr_mean, r2_cr_std   = np.mean(r2_cr_scores), np.std(r2_cr_scores)

# Co
mse_co_mean, mse_co_std = np.mean(mse_co_scores), np.std(mse_co_scores)
r2_co_mean, r2_co_std   = np.mean(r2_co_scores), np.std(r2_co_scores)

# Print results
print(f"Temperature: MSE = {mse_temp_mean:.4f} ± {mse_temp_std:.4f}, R² = {r2_temp_mean:.4f} ± {r2_temp_std:.4f}")
print(f"Cr: MSE = {mse_cr_mean:.4f} ± {mse_cr_std:.4f}, R² = {r2_cr_mean:.4f} ± {r2_cr_std:.4f}")
print(f"Co: MSE = {mse_co_mean:.4f} ± {mse_co_std:.4f}, R² = {r2_co_mean:.4f} ± {r2_co_std:.4f}")

# Temperature
parity_plot(
    all_targets_temp, all_preds_temp,
    max_value=maxTemp,
    plot_name="combined_parity_temp.png",
    label="Temperature ",
    custom_ticks=True, tick_interval=20,
    mse_mean=mse_temp_mean, mse_std=mse_temp_std,
    r2_mean=r2_temp_mean, r2_std=r2_temp_std
)

# Cr
parity_plot(
    all_targets_cr, all_preds_cr,
    lims_min=0, lims_max=1,
    plot_name="combined_parity_cr.png",
    label="Cr ",
    mse_mean=mse_cr_mean, mse_std=mse_cr_std,
    r2_mean=r2_cr_mean, r2_std=r2_cr_std
)

# Co
parity_plot(
    all_targets_co, all_preds_co,
    lims_min=0, lims_max=1,
    plot_name="combined_parity_co.png",
    label="Co ",
    mse_mean=mse_co_mean, mse_std=mse_co_std,
    r2_mean=r2_co_mean, r2_std=r2_co_std
)



