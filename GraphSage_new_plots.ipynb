{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08c9dc4c-14e9-4e5f-98bd-d77b9ceada66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Data objects created: 386\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import igraph as ig\n",
    "import os\n",
    "import glob\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Read the Excel file\n",
    "df = pd.read_excel('Data_NoTime.xlsx')\n",
    "\n",
    "# Calculate the maximum values for normalization\n",
    "#max_time = df['time'].max()\n",
    "max_temperature = df['temperature'].max()\n",
    "\n",
    "# Normalize 'time' and 'temperature' using the maximum values\n",
    "#df['time'] = df['time'] / max_time\n",
    "df['temperature'] = df['temperature'] / max_temperature\n",
    "\n",
    "# Create a dictionary to map filenames to their target values\n",
    "#file_to_targets = {row[\"image_name\"]: [row[\"Cr\"], row[\"Co\"], row[\"temperature\"], row[\"time\"]] for _, row in df.iterrows()}\n",
    "file_to_targets = {row[\"image_name\"]: [row[\"Cr\"], row[\"Co\"], row[\"temperature\"]] for _, row in df.iterrows()}\n",
    "\n",
    "# Define the path to the GraphML files directory and process each GraphML file\n",
    "graphml_dir_path = \"Graph_Generation\"\n",
    "data_list = []\n",
    "\n",
    "for graphml_file_path in glob.glob(os.path.join(graphml_dir_path, \"*.graphml\")):\n",
    "    filename = os.path.basename(graphml_file_path)\n",
    "    \n",
    "    if filename in file_to_targets:\n",
    "        # Load the graph using igraph\n",
    "        graph = ig.Graph.Read_GraphML(graphml_file_path)\n",
    "\n",
    "        # Extract node features\n",
    "        node_features = [[vertex['value']] for vertex in graph.vs]\n",
    "        edge_indices = [[edge.source, edge.target] for edge in graph.es]\n",
    "        edge_attrs = [[edge['weight']] for edge in graph.es]\n",
    "\n",
    "        # Convert to PyTorch tensors\n",
    "        x = torch.tensor(node_features, dtype=torch.float)\n",
    "        edge_index = torch.tensor(edge_indices, dtype=torch.long).t().contiguous()\n",
    "        edge_attr = torch.tensor(edge_attrs, dtype=torch.float)\n",
    "\n",
    "        # Get the target values for this graph\n",
    "        target = torch.tensor(file_to_targets[filename], dtype=torch.float32)\n",
    "\n",
    "        # Reshape target to [1, 4] (assuming each graph has exactly one target)\n",
    "        #target_reshaped = target.view(1, 3)\n",
    "        target_reshaped = target.view(-1, 3)  # Make sure the target has the shape [batch_size, 3]\n",
    "\n",
    "\n",
    "        # Create PyTorch Geometric Data object\n",
    "        data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=target_reshaped)\n",
    "        #print(\"data.x\",data.x)\n",
    "        data_list.append(data)\n",
    "\n",
    "# Print the number of Data objects created\n",
    "print(f\"Number of Data objects created: {len(data_list)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df890bb7-4c23-4ed1-8741-f9c9c7efcad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cr</th>\n",
       "      <th>Co</th>\n",
       "      <th>temperature</th>\n",
       "      <th>image_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.886598</td>\n",
       "      <td>cr0.45_co0.35_T860_360000.graphml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.896907</td>\n",
       "      <td>cr0.45_co0.35_T870_360000.graphml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.927835</td>\n",
       "      <td>cr0.45_co0.25_T900_360000.graphml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.907216</td>\n",
       "      <td>cr0.45_co0.35_T880_360000.graphml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.938144</td>\n",
       "      <td>cr0.45_co0.25_T910_360000.graphml</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cr    Co  temperature                         image_name\n",
       "0  0.45  0.35     0.886598  cr0.45_co0.35_T860_360000.graphml\n",
       "1  0.45  0.35     0.896907  cr0.45_co0.35_T870_360000.graphml\n",
       "2  0.45  0.25     0.927835  cr0.45_co0.25_T900_360000.graphml\n",
       "3  0.45  0.35     0.907216  cr0.45_co0.35_T880_360000.graphml\n",
       "4  0.45  0.25     0.938144  cr0.45_co0.25_T910_360000.graphml"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cca6053-7641-470a-8ac5-665222b2eb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 308\n",
      "Number of testing samples: 78\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# Split data_list into training and testing sets\n",
    "train_data, test_data = train_test_split(data_list, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create DataLoader instances for training and testing data\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "# Print the number of training and testing samples\n",
    "print(f\"Number of training samples: {len(train_data)}\")\n",
    "print(f\"Number of testing samples: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "283d3661-c1aa-4fc8-b907-c5880c63fc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv, global_mean_pool\n",
    "\n",
    "# Define the GraphSAGE model with weight initialization\n",
    "class GraphSAGEModel(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, hidden_channels=128):\n",
    "        super(GraphSAGEModel, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels, aggr='mean')\n",
    "        self.conv2 = SAGEConv(hidden_channels, hidden_channels, aggr='mean')\n",
    "        self.conv3 = SAGEConv(hidden_channels, hidden_channels, aggr='mean')\n",
    "        self.conv4 = SAGEConv(hidden_channels, hidden_channels, aggr='mean')\n",
    "        self.conv5 = SAGEConv(hidden_channels, hidden_channels, aggr='mean')\n",
    "        self.conv6 = SAGEConv(hidden_channels, hidden_channels, aggr='mean')\n",
    "        self.conv7 = SAGEConv(hidden_channels, hidden_channels, aggr='mean')\n",
    "        self.conv8 = SAGEConv(hidden_channels, hidden_channels, aggr='mean')\n",
    "        self.fc1 = nn.Linear(hidden_channels, hidden_channels)\n",
    "        self.fc2 = nn.Linear(hidden_channels, hidden_channels)\n",
    "        self.fc3 = nn.Linear(hidden_channels, hidden_channels)\n",
    "        self.fc4 = nn.Linear(hidden_channels, hidden_channels)\n",
    "        self.fc5 = nn.Linear(hidden_channels, out_channels)\n",
    "\n",
    "        # Apply weight initialization\n",
    "        self.initialize_weights()\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, SAGEConv):\n",
    "                # Apply Xavier initialization for GraphSAGE layers\n",
    "                torch.nn.init.xavier_uniform_(m.lin_l.weight)\n",
    "                torch.nn.init.xavier_uniform_(m.lin_r.weight)\n",
    "                if m.lin_l.bias is not None:\n",
    "                    torch.nn.init.zeros_(m.lin_l.bias)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                # Apply He initialization for fully connected layers\n",
    "                torch.nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    torch.nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = F.relu(self.conv3(x, edge_index))\n",
    "        x = F.relu(self.conv4(x, edge_index))\n",
    "        x = F.relu(self.conv5(x, edge_index))\n",
    "        x = F.relu(self.conv6(x, edge_index))\n",
    "        x = F.relu(self.conv7(x, edge_index))\n",
    "        x = F.relu(self.conv8(x, edge_index))\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.fc5(x)  # No activation in the final layer\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = GraphSAGEModel(in_channels=1, out_channels=3)\n",
    "\n",
    "# Optimizer and loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.L1Loss()  # Mean Absolute Error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a332eedd-421a-458e-bd77-b1759a0b0cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Train Loss: 0.1052\n",
      "Epoch 2/50, Train Loss: 0.0768\n",
      "Epoch 3/50, Train Loss: 0.0757\n",
      "Epoch 4/50, Train Loss: 0.0733\n",
      "Epoch 5/50, Train Loss: 0.0711\n",
      "Epoch 6/50, Train Loss: 0.0698\n",
      "Epoch 7/50, Train Loss: 0.0680\n",
      "Epoch 8/50, Train Loss: 0.0679\n",
      "Epoch 9/50, Train Loss: 0.0662\n",
      "Epoch 10/50, Train Loss: 0.0666\n",
      "Epoch 11/50, Train Loss: 0.0657\n",
      "Epoch 12/50, Train Loss: 0.0644\n",
      "Epoch 13/50, Train Loss: 0.0641\n",
      "Epoch 14/50, Train Loss: 0.0626\n",
      "Epoch 15/50, Train Loss: 0.0629\n",
      "Epoch 16/50, Train Loss: 0.0610\n",
      "Epoch 17/50, Train Loss: 0.0607\n",
      "Epoch 18/50, Train Loss: 0.0610\n",
      "Epoch 19/50, Train Loss: 0.0608\n",
      "Epoch 20/50, Train Loss: 0.0596\n",
      "Epoch 21/50, Train Loss: 0.0589\n",
      "Epoch 22/50, Train Loss: 0.0577\n",
      "Epoch 23/50, Train Loss: 0.0600\n",
      "Epoch 24/50, Train Loss: 0.0565\n",
      "Epoch 25/50, Train Loss: 0.0566\n",
      "Epoch 26/50, Train Loss: 0.0572\n",
      "Epoch 27/50, Train Loss: 0.0588\n",
      "Epoch 28/50, Train Loss: 0.0556\n",
      "Epoch 29/50, Train Loss: 0.0553\n",
      "Epoch 30/50, Train Loss: 0.0529\n",
      "Epoch 31/50, Train Loss: 0.0499\n",
      "Epoch 32/50, Train Loss: 0.0431\n",
      "Epoch 33/50, Train Loss: 0.0425\n",
      "Epoch 34/50, Train Loss: 0.0391\n",
      "Epoch 35/50, Train Loss: 0.0394\n",
      "Epoch 36/50, Train Loss: 0.0374\n",
      "Epoch 37/50, Train Loss: 0.0341\n",
      "Epoch 38/50, Train Loss: 0.0356\n",
      "Epoch 39/50, Train Loss: 0.0345\n",
      "Epoch 40/50, Train Loss: 0.0306\n",
      "Epoch 41/50, Train Loss: 0.0311\n",
      "Epoch 42/50, Train Loss: 0.0331\n",
      "Epoch 43/50, Train Loss: 0.0285\n",
      "Epoch 44/50, Train Loss: 0.0280\n",
      "Epoch 45/50, Train Loss: 0.0301\n",
      "Epoch 46/50, Train Loss: 0.0300\n",
      "Epoch 47/50, Train Loss: 0.0266\n",
      "Epoch 48/50, Train Loss: 0.0297\n",
      "Epoch 49/50, Train Loss: 0.0281\n",
      "Epoch 50/50, Train Loss: 0.0272\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import csv\n",
    "\n",
    "def train(loader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    train_predictions = []\n",
    "    train_targets = []\n",
    "\n",
    "    for batch_idx, batch in enumerate(loader):\n",
    "        batch.x.requires_grad = True\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n",
    "\n",
    "        loss = criterion(out, batch.y)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        train_predictions.append(out)\n",
    "        train_targets.append(batch.y)\n",
    "\n",
    "    predictions = torch.cat(train_predictions, dim=0)\n",
    "    targets = torch.cat(train_targets, dim=0)\n",
    "\n",
    "    return total_loss / len(loader), predictions, targets\n",
    "\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    test_predictions = []\n",
    "    test_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(loader):\n",
    "            out = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n",
    "\n",
    "            loss = criterion(out, batch.y)\n",
    "            total_loss += loss.item()\n",
    "            test_predictions.append(out)\n",
    "            test_targets.append(batch.y)\n",
    "\n",
    "    predictions = torch.cat(test_predictions, dim=0)\n",
    "    targets = torch.cat(test_targets, dim=0)\n",
    "\n",
    "    return total_loss / len(loader), predictions, targets\n",
    "\n",
    "\n",
    "# Logging and plotting data\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "# Training loop with testing\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    train_loss, train_predictions, train_targets = train(train_data)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # Extract individual predictions and true values for Cr, Co, and temperature\n",
    "    pred_Cr_train, pred_Co_train, pred_temperature_train = train_predictions[:, 0], train_predictions[:, 1], train_predictions[:, 2]\n",
    "    true_Cr_train, true_Co_train, true_temperature_train = train_targets[:, 0], train_targets[:, 1], train_targets[:, 2]\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}\")\n",
    "\n",
    "    # Testing\n",
    "    test_loss, test_predictions, test_targets = test(test_data)\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "    pred_Cr_test, pred_Co_test, pred_temperature_test = test_predictions[:, 0], test_predictions[:, 1], test_predictions[:, 2]\n",
    "    true_Cr_test, true_Co_test, true_temperature_test = test_targets[:, 0], test_targets[:, 1], test_targets[:, 2]\n",
    "\n",
    "# Save train and test losses to a CSV file\n",
    "with open('losses.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Epoch', 'Train Loss', 'Test Loss'])\n",
    "    for epoch in range(num_epochs):\n",
    "        writer.writerow([epoch+1, train_losses[epoch], test_losses[epoch]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dde9ce6-53aa-475e-b198-413ba3c09611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 true and predicted values for Time and Temperature:\n",
      "True Temperature: 0.979, Pred Temperature: 0.987\n",
      "True Temperature: 0.959, Pred Temperature: 0.970\n",
      "True Temperature: 0.959, Pred Temperature: 0.970\n",
      "True Temperature: 0.918, Pred Temperature: 0.926\n",
      "True Temperature: 0.990, Pred Temperature: 0.991\n",
      "True Temperature: 0.959, Pred Temperature: 0.985\n",
      "True Temperature: 0.959, Pred Temperature: 0.969\n",
      "True Temperature: 0.938, Pred Temperature: 0.936\n",
      "True Temperature: 0.969, Pred Temperature: 0.963\n",
      "True Temperature: 0.887, Pred Temperature: 0.861\n"
     ]
    }
   ],
   "source": [
    "# Print first 10 values for true and predicted time and temperature\n",
    "print(\"First 10 true and predicted values for Time and Temperature:\")\n",
    "for i in range(10):\n",
    "    #print(f\"True Time: {true_time[i].item():.3f}, Pred Time: {pred_time[i].item():.3f}\")\n",
    "    print(f\"True Temperature: {true_temperature_train[i].item():.3f}, Pred Temperature: {pred_temperature_train[i].item():.3f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b24ee3da-b8f1-47f7-a723-16f03bb33101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 true and predicted values for Cr and Co:\n",
      "True Cr: 0.300, Pred Cr: 0.271\n",
      "True Cr: 0.400, Pred Cr: 0.386\n",
      "True Cr: 0.450, Pred Cr: 0.448\n",
      "True Cr: 0.500, Pred Cr: 0.472\n",
      "True Cr: 0.350, Pred Cr: 0.309\n",
      "True Cr: 0.300, Pred Cr: 0.265\n",
      "True Cr: 0.400, Pred Cr: 0.371\n",
      "True Cr: 0.400, Pred Cr: 0.339\n",
      "True Cr: 0.400, Pred Cr: 0.394\n",
      "True Cr: 0.400, Pred Cr: 0.392\n"
     ]
    }
   ],
   "source": [
    "print(\"First 10 true and predicted values for Cr and Co:\")\n",
    "for i in range(10):\n",
    "    print(f\"True Cr: {true_Cr_train[i].item():.3f}, Pred Cr: {pred_Cr_train[i].item():.3f}\")\n",
    "    #print(f\"True Co: {true_Co[i].item():.3f}, Pred Co: {pred_Co[i].item():.3f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1aa6420-2af8-47d3-b211-79e1374dbf04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 true and predicted values for Cr and Co:\n",
      "True Co: 0.250, Pred Co: 0.217\n",
      "True Co: 0.350, Pred Co: 0.312\n",
      "True Co: 0.300, Pred Co: 0.251\n",
      "True Co: 0.250, Pred Co: 0.230\n",
      "True Co: 0.400, Pred Co: 0.477\n",
      "True Co: 0.200, Pred Co: 0.289\n",
      "True Co: 0.150, Pred Co: 0.209\n",
      "True Co: 0.300, Pred Co: 0.499\n",
      "True Co: 0.150, Pred Co: 0.197\n",
      "True Co: 0.450, Pred Co: 0.482\n"
     ]
    }
   ],
   "source": [
    "print(\"First 10 true and predicted values for Cr and Co:\")\n",
    "for i in range(10):\n",
    "    #print(f\"True Cr: {true_Cr[i].item():.3f}, Pred Cr: {pred_Cr[i].item():.3f}\")\n",
    "    print(f\"True Co: {true_Co_train[i].item():.3f}, Pred Co: {pred_Co_train[i].item():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b9a2154-a50c-4042-8804-b0fb7597d9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 denormalized true and predicted values for Temperature:\n",
      "True Temp: 950.00, Pred Temp: 957.54\n",
      "True Temp: 930.00, Pred Temp: 941.23\n",
      "True Temp: 930.00, Pred Temp: 941.11\n",
      "True Temp: 890.00, Pred Temp: 898.33\n",
      "True Temp: 960.00, Pred Temp: 961.57\n",
      "True Temp: 930.00, Pred Temp: 955.77\n",
      "True Temp: 930.00, Pred Temp: 939.92\n",
      "True Temp: 910.00, Pred Temp: 907.57\n",
      "True Temp: 940.00, Pred Temp: 934.50\n",
      "True Temp: 860.00, Pred Temp: 834.75\n"
     ]
    }
   ],
   "source": [
    "# Denormalize temperature values\n",
    "true_temp_denorm = true_temperature_train * max_temperature\n",
    "pred_temp_denorm = pred_temperature_train * max_temperature\n",
    "print(\"First 10 denormalized true and predicted values for Temperature:\")\n",
    "for i in range(10):\n",
    "    print(f\"True Temp: {true_temp_denorm[i]:.2f}, Pred Temp: {pred_temp_denorm[i]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc9b2176-a12f-4622-9ec6-f2a82e3c6467",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7331/3137613047.py:32: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  plt.legend().remove()\n",
      "/tmp/ipykernel_7331/3137613047.py:32: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  plt.legend().remove()\n",
      "/tmp/ipykernel_7331/3137613047.py:32: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  plt.legend().remove()\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Extract individual predictions and true values for Cr, Co, and temperature\n",
    "pred_Cr_train, pred_Co_train, pred_temperature_train = train_predictions[:, 0], train_predictions[:, 1], train_predictions[:, 2]\n",
    "true_Cr_train, true_Co_train, true_temperature_train = train_targets[:, 0], train_targets[:, 1], train_targets[:, 2]\n",
    "\n",
    "\n",
    "def parity_plot(ground_truth, prediction,\n",
    "                lims_min, lims_max,\n",
    "                plot_name, r2_value=None,\n",
    "                ground_truth_norm=None, prediction_norm=None):\n",
    "    # plt.figure()\n",
    "    plt.figure(figsize=(3.5, 3.5), dpi=200)\n",
    "\n",
    "    # Scatter plot of true vs predicted values\n",
    "    plt.scatter(ground_truth, prediction,  color='black', s=8)\n",
    "    \n",
    "    # Define the line for perfect prediction\n",
    "    plt.plot([lims_min, lims_max], [lims_min, lims_max], 'k--',linewidth=1)\n",
    "    \n",
    "    # Set limits for x and y axes to the range of your data\n",
    "    plt.xlim(lims_min, lims_max)  # X-axis limit\n",
    "    plt.ylim(lims_min, lims_max)  # Y-axis limit\n",
    "    \n",
    "    # Add labels, title, legend, and grid\n",
    "    plt.xlabel('Ground Truth', fontsize=20, labelpad=4)\n",
    "    plt.ylabel('Prediction', fontsize=20, labelpad=4)\n",
    "    plt.title(plot_name, fontsize=20,loc='center')\n",
    "    plt.legend().remove()\n",
    "    plt.grid(False)\n",
    "    plt.tick_params(axis='both', which='both', length=0)\n",
    "    \n",
    "    # Calculate MSE\n",
    "    # mse = mean_squared_error(ground_truth, prediction)\n",
    "    # Use normalized values if provided, otherwise fall back to original values\n",
    "    gt_mse = ground_truth_norm if ground_truth_norm is not None else ground_truth\n",
    "    pred_mse = prediction_norm if prediction_norm is not None else prediction\n",
    "    mse = mean_squared_error(gt_mse, pred_mse)\n",
    "#     # Add R² and MSE as text to the plot\n",
    "#     plt.text(\n",
    "#         0.05, 0.95, \n",
    "#         f\"R-Squared = {r2_value:.3f}\\nMSE = {mse:.2E}\", \n",
    "#         transform=plt.gca().transAxes,\n",
    "#         fontsize=10,\n",
    "#         verticalalignment='top')\n",
    "    \n",
    "#     # Show the plot\n",
    "#     #plt.show()\n",
    "#     plt.savefig(file_path)\n",
    "#     plt.close()\n",
    "    # Display normalized MSE and R²\n",
    "    plt.text(\n",
    "        0.02, 0.98,\n",
    "        f'$\\\\bf{{R-Squared}}$ = {r2_value:.4f}\\n$\\\\bf{{MSE}}$ = {mse:.1E}',\n",
    "        fontsize=20,\n",
    "        color='black',\n",
    "        ha='left',\n",
    "        va='top',\n",
    "        transform=plt.gca().transAxes\n",
    "    ) \n",
    "    plt.tight_layout(pad=0.5)\n",
    "    plt.savefig(plot_name,dpi=150, facecolor='w', edgecolor='w')\n",
    "    plt.close()\n",
    "\n",
    "    # Example usage\n",
    "# true_temperature = true_temperature_train.numpy()\n",
    "# pred_temperature = pred_temperature_train.detach().numpy()  # Detach the tensor before calling .numpy()\n",
    "\n",
    "# Normalized values (already between 0 and 1)\n",
    "true_temp_norm = true_temperature_train.numpy()\n",
    "pred_temp_norm = pred_temperature_train.detach().numpy()\n",
    "\n",
    "# Denormalized values\n",
    "true_temp_denorm = true_temp_norm * max_temperature\n",
    "pred_temp_denorm = pred_temp_norm * max_temperature\n",
    "\n",
    "# Calculate R²\n",
    "r2_temperature = r2_score(true_temp_norm, pred_temp_norm)\n",
    "\n",
    "# Define plot limits based on your data range\n",
    "lims_min = min(true_temp_denorm.min(), pred_temp_denorm.min())\n",
    "lims_max = max(true_temp_denorm.max(), pred_temp_denorm.max())\n",
    "\n",
    "\n",
    "# Call the function\n",
    "# parity_plot(true_temperature, pred_temperature, lims_min, lims_max,  \"predicted_temperature.png\",r2_value=r2_temperature)\n",
    "parity_plot(\n",
    "    ground_truth=true_temp_denorm,\n",
    "    prediction=pred_temp_denorm,\n",
    "    lims_min=lims_min, lims_max=lims_max,\n",
    "    plot_name=\"temerpature_train.png\",\n",
    "    r2_value=r2_temperature,\n",
    "    ground_truth_norm=true_temp_norm,\n",
    "    prediction_norm=pred_temp_norm\n",
    ")\n",
    "\n",
    "\n",
    "pred_Cr = pred_Cr_train.detach().numpy()\n",
    "true_Cr = true_Cr_train.numpy()\n",
    "\n",
    "# Calculate R²\n",
    "r2_Cr = r2_score(true_Cr, pred_Cr)\n",
    "\n",
    "# Call the function\n",
    "# parity_plot(true_Cr, pred_Cr, 0, 1,'parity_plot_Cr.png',r2_value=r2_Cr)\n",
    "parity_plot(\n",
    "    ground_truth=true_Cr,\n",
    "    prediction=pred_Cr,\n",
    "    lims_min=0, lims_max=1,\n",
    "    plot_name=\"Cr_train\",\n",
    "    r2_value=r2_score(true_Cr, pred_Cr)\n",
    ")\n",
    "pred_Co = pred_Co_train.detach().numpy()\n",
    "true_Co = true_Co_train.numpy()\n",
    "\n",
    "# Calculate R²\n",
    "r2_Co = r2_score(true_Co, pred_Co)\n",
    "\n",
    "\n",
    "# Call the function\n",
    "# parity_plot(true_Co, pred_Co, 0, 1, 'parity_plot_Co.png',r2_value=r2_Co)\n",
    "parity_plot(\n",
    "    ground_truth=true_Co,\n",
    "    prediction=pred_Co,\n",
    "    lims_min=0, lims_max=1,\n",
    "    plot_name=\"Co_train\",\n",
    "    r2_value=r2_score(true_Co, pred_Co)\n",
    ")\n",
    "\n",
    "# Convert to numpy for plotting\n",
    "#pred_time = pred_time.numpy()\n",
    "#true_time = true_time.numpy()\n",
    "\n",
    "\n",
    "# Plot name for Cr component\n",
    "#plot_name_time = \"Parity Plot: True vs. Predicted time\"\n",
    "\n",
    "# Call the function\n",
    "#parity_plot(true_time, pred_time, lims_min, lims_max, plot_name_time,'parity_plot_time.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "151852b1-9d41-44b0-97fa-cfc5ecc563ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7331/2506608229.py:31: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  plt.legend().remove()\n",
      "/tmp/ipykernel_7331/2506608229.py:31: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  plt.legend().remove()\n",
      "/tmp/ipykernel_7331/2506608229.py:31: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  plt.legend().remove()\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "pred_Cr_test, pred_Co_test, pred_temperature_test = test_predictions[:, 0], test_predictions[:, 1], test_predictions[:, 2]\n",
    "true_Cr_test, true_Co_test, true_temperature_test = test_targets[:, 0], test_targets[:, 1], test_targets[:, 2]\n",
    "\n",
    "\n",
    "def parity_plot(ground_truth, prediction,\n",
    "                lims_min, lims_max,\n",
    "                plot_name, r2_value=None,\n",
    "                ground_truth_norm=None, prediction_norm=None):\n",
    "    # plt.figure()\n",
    "    plt.figure(figsize=(3.5,3.5), dpi=200)\n",
    "\n",
    "    # Scatter plot of true vs predicted values\n",
    "    plt.scatter(ground_truth, prediction,  color='black', s=5)\n",
    "    \n",
    "    # Define the line for perfect prediction\n",
    "    plt.plot([lims_min, lims_max], [lims_min, lims_max], 'k--',linewidth=1)\n",
    "    \n",
    "    # Set limits for x and y axes to the range of your data\n",
    "    plt.xlim(lims_min, lims_max)  # X-axis limit\n",
    "    plt.ylim(lims_min, lims_max)  # Y-axis limit\n",
    "    \n",
    "    # Add labels, title, legend, and grid\n",
    "    plt.xlabel('Ground Truth', fontsize=25, labelpad=4)\n",
    "    plt.ylabel('Prediction', fontsize=25, labelpad=4)\n",
    "    plt.title(plot_name, fontsize=20,loc='center')\n",
    "    plt.legend().remove()\n",
    "    plt.grid(False)\n",
    "    plt.tick_params(axis='both', which='both', length=0)\n",
    "    \n",
    "    # Calculate MSE\n",
    "    # mse = mean_squared_error(ground_truth, prediction)\n",
    "    # Use normalized values if provided, otherwise fall back to original values\n",
    "    gt_mse = ground_truth_norm if ground_truth_norm is not None else ground_truth\n",
    "    pred_mse = prediction_norm if prediction_norm is not None else prediction\n",
    "    mse = mean_squared_error(gt_mse, pred_mse)\n",
    "#     # Add R² and MSE as text to the plot\n",
    "#     plt.text(\n",
    "#         0.05, 0.95, \n",
    "#         f\"R-Squared = {r2_value:.3f}\\nMSE = {mse:.2E}\", \n",
    "#         transform=plt.gca().transAxes,\n",
    "#         fontsize=10,\n",
    "#         verticalalignment='top')\n",
    "    \n",
    "#     # Show the plot\n",
    "#     #plt.show()\n",
    "#     plt.savefig(file_path)\n",
    "#     plt.close()\n",
    "    # Display normalized MSE and R²\n",
    "    plt.text(\n",
    "        0.02, 0.98,\n",
    "        f'$\\\\bf{{R-Squared}}$ = {r2_value:.4f}\\n$\\\\bf{{MSE}}$ = {mse:.1E}',\n",
    "        fontsize=16,\n",
    "        color='black',\n",
    "        ha='left',\n",
    "        va='top',\n",
    "        transform=plt.gca().transAxes,\n",
    "       \n",
    "    ) \n",
    "    plt.tight_layout(pad=0.5)\n",
    "    plt.savefig(plot_name,dpi=200, facecolor='w', edgecolor='w')\n",
    "    plt.close()\n",
    "\n",
    "    # Example usage\n",
    "# true_temperature = true_temperature_train.numpy()\n",
    "# pred_temperature = pred_temperature_train.detach().numpy()  # Detach the tensor before calling .numpy()\n",
    "\n",
    "# Normalized values (already between 0 and 1)\n",
    "true_temp_norm = true_temperature_test.numpy()\n",
    "pred_temp_norm = pred_temperature_test.detach().numpy()\n",
    "\n",
    "# Denormalized values\n",
    "true_temp_denorm = true_temp_norm * max_temperature\n",
    "pred_temp_denorm = pred_temp_norm * max_temperature\n",
    "\n",
    "# Calculate R²\n",
    "r2_temperature = r2_score(true_temp_norm, pred_temp_norm)\n",
    "\n",
    "# Define plot limits based on your data range\n",
    "lims_min = min(true_temp_denorm.min(), pred_temp_denorm.min())\n",
    "lims_max = max(true_temp_denorm.max(), pred_temp_denorm.max())\n",
    "\n",
    "# Call the function\n",
    "# parity_plot(true_temperature, pred_temperature, lims_min, lims_max,  \"predicted_temperature.png\",r2_value=r2_temperature)\n",
    "parity_plot(\n",
    "    ground_truth=true_temp_denorm,\n",
    "    prediction=pred_temp_denorm,\n",
    "    lims_min=lims_min, lims_max=lims_max,\n",
    "    plot_name=\"temperature\",\n",
    "    r2_value=r2_temperature,\n",
    "    ground_truth_norm=true_temp_norm,\n",
    "    prediction_norm=pred_temp_norm\n",
    ")\n",
    "\n",
    "\n",
    "pred_Cr = pred_Cr_test.detach().numpy()\n",
    "true_Cr = true_Cr_test.numpy()\n",
    "\n",
    "# Calculate R²\n",
    "r2_Cr = r2_score(true_Cr, pred_Cr)\n",
    "\n",
    "# Call the function\n",
    "# parity_plot(true_Cr, pred_Cr, 0, 1,'parity_plot_Cr.png',r2_value=r2_Cr)\n",
    "parity_plot(\n",
    "    ground_truth=true_Cr,\n",
    "    prediction=pred_Cr,\n",
    "    lims_min=0, lims_max=1,\n",
    "    plot_name=\"Cr\",\n",
    "    r2_value=r2_score(true_Cr, pred_Cr)\n",
    ")\n",
    "pred_Co = pred_Co_test.detach().numpy()\n",
    "true_Co = true_Co_test.numpy()\n",
    "\n",
    "# Calculate R²\n",
    "r2_Co = r2_score(true_Co, pred_Co)\n",
    "\n",
    "# Call the function\n",
    "# parity_plot(true_Co, pred_Co, 0, 1, 'parity_plot_Co.png',r2_value=r2_Co)\n",
    "parity_plot(\n",
    "    ground_truth=true_Co,\n",
    "    prediction=pred_Co,\n",
    "    lims_min=0, lims_max=1,\n",
    "    plot_name=\"Co\",\n",
    "    r2_value=r2_score(true_Co, pred_Co)\n",
    ")\n",
    "\n",
    "# Convert to numpy for plotting\n",
    "#pred_time = pred_time.numpy()\n",
    "#true_time = true_time.numpy()\n",
    "\n",
    "\n",
    "# Plot name for Cr component\n",
    "#plot_name_time = \"Parity Plot: True vs. Predicted time\"\n",
    "\n",
    "# Call the function\n",
    "#parity_plot(true_time, pred_time, lims_min, lims_max, plot_name_time,'parity_plot_time.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "061f25e4-56aa-44cd-b80b-a8d9b215d8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('losses.csv')\n",
    "\n",
    "# Output directory\n",
    "os.makedirs('learning_curves', exist_ok=True)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(5, 3), dpi=300)\n",
    "\n",
    "# Plot with smooth, professional lines\n",
    "plt.plot(data['Epoch'], data['Train Loss'], label='Train loss', color='red', linewidth=2)\n",
    "plt.plot(data['Epoch'], data['Test Loss'], label='Validation loss', color='green', linestyle='--', linewidth=2)\n",
    "\n",
    "# Axis labels\n",
    "plt.xlabel('Epoch', fontsize=14)\n",
    "plt.ylabel('Loss', fontsize=14)\n",
    "\n",
    "# Ticks and formatting\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.tick_params(axis='both', which='both', direction='out', length=4)\n",
    "\n",
    "# Optional: fix y-scale for visual consistency\n",
    "#plt.ylim(bottom=0, top=100)  # Use if you want to stretch the vertical axis\n",
    "\n",
    "# Legend\n",
    "plt.legend(fontsize=12, loc='upper right', frameon=False)\n",
    "\n",
    "# Clean layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save as high-resolution PNG (or PDF)\n",
    "plt.savefig('learning_curves/gnn_learning_curve_pubready.png', dpi=300)\n",
    "# plt.savefig('learning_curves/gnn_learning_curve_pubready.pdf', format='pdf')\n",
    "\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86618d52-3d0a-4a28-86f5-8001616f4535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 test true and predicted values for Time and Temperature:\n",
      "True Temperature: 1.000, Pred Temperature: 0.993\n",
      "True Temperature: 0.928, Pred Temperature: 0.946\n",
      "True Temperature: 0.887, Pred Temperature: 0.933\n",
      "True Temperature: 0.948, Pred Temperature: 0.966\n",
      "True Temperature: 0.990, Pred Temperature: 0.979\n",
      "True Temperature: 0.897, Pred Temperature: 0.894\n",
      "True Temperature: 0.907, Pred Temperature: 0.917\n",
      "True Temperature: 0.938, Pred Temperature: 0.951\n",
      "True Temperature: 0.928, Pred Temperature: 0.931\n",
      "True Temperature: 0.928, Pred Temperature: 0.954\n"
     ]
    }
   ],
   "source": [
    "# Print first 10 values for true and predicted time and temperature\n",
    "print(\"First 10 test true and predicted values for Time and Temperature:\")\n",
    "for i in range(10):\n",
    "    #print(f\"True Time: {true_time[i].item():.3f}, Pred Time: {pred_time[i].item():.3f}\")\n",
    "    print(f\"True Temperature: {true_temperature_test[i].item():.3f}, Pred Temperature: {pred_temperature_test[i].item():.3f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14d35222-df20-456c-af2f-a1d3246c2a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10  test true and predicted values for Cr and Co:\n",
      "True Cr: 0.300, Pred Cr: 0.297\n",
      "True Cr: 0.300, Pred Cr: 0.301\n",
      "True Cr: 0.450, Pred Cr: 0.463\n",
      "True Cr: 0.300, Pred Cr: 0.305\n",
      "True Cr: 0.250, Pred Cr: 0.304\n",
      "True Cr: 0.400, Pred Cr: 0.440\n",
      "True Cr: 0.350, Pred Cr: 0.361\n",
      "True Cr: 0.300, Pred Cr: 0.306\n",
      "True Cr: 0.450, Pred Cr: 0.411\n",
      "True Cr: 0.400, Pred Cr: 0.394\n"
     ]
    }
   ],
   "source": [
    "print(\"First 10  test true and predicted values for Cr and Co:\")\n",
    "for i in range(10):\n",
    "    print(f\"True Cr: {true_Cr_test[i].item():.3f}, Pred Cr: {pred_Cr_test[i].item():.3f}\")\n",
    "    #print(f\"True Co: {true_Co[i].item():.3f}, Pred Co: {pred_Co[i].item():.3f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c47dc670-0beb-43cc-b40a-8a945f22eec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 test true and predicted values for Cr and Co:\n",
      "True Co: 0.200, Pred Co: 0.183\n",
      "True Co: 0.300, Pred Co: 0.331\n",
      "True Co: 0.100, Pred Co: 0.078\n",
      "True Co: 0.250, Pred Co: 0.267\n",
      "True Co: 0.600, Pred Co: 0.462\n",
      "True Co: 0.450, Pred Co: 0.382\n",
      "True Co: 0.350, Pred Co: 0.308\n",
      "True Co: 0.300, Pred Co: 0.309\n",
      "True Co: 0.400, Pred Co: 0.474\n",
      "True Co: 0.150, Pred Co: 0.179\n"
     ]
    }
   ],
   "source": [
    "print(\"First 10 test true and predicted values for Cr and Co:\")\n",
    "for i in range(10):\n",
    "    #print(f\"True Cr: {true_Cr[i].item():.3f}, Pred Cr: {pred_Cr[i].item():.3f}\")\n",
    "    print(f\"True Co: {true_Co_test[i].item():.3f}, Pred Co: {pred_Co_test[i].item():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91fe2fe3-da31-4f59-998c-10381ec1af19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7331/2253312636.py:26: UserWarning: First parameter to grid() is false, but line properties are supplied. The grid will be enabled.\n",
      "  plt.grid(False, which=\"both\", linestyle='--', linewidth=0.5)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data (example assumes you have it in a CSV file or as a DataFrame)\n",
    "# Replace 'file_path.csv' with your file path\n",
    "data = pd.read_csv('losses.csv')\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs('logplot', exist_ok=True)\n",
    "\n",
    "# Extract values for plotting\n",
    "epochs = data['Epoch']\n",
    "train_loss = data['Train Loss']\n",
    "test_loss = data['Test Loss']\n",
    "\n",
    "# Create a log plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.semilogy(epochs, train_loss, label='Train Loss', color='blue')\n",
    "plt.semilogy(epochs, test_loss, label='Test Loss', color='red')\n",
    "\n",
    "# Add labels, title, and legend\n",
    "plt.xlabel('Epoch', fontsize=14)\n",
    "plt.ylabel('Loss (Log Scale)', fontsize=14)\n",
    "plt.title('Training and Testing Loss (Log Scale)', fontsize=16)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(False, which=\"both\", linestyle='--', linewidth=0.5)\n",
    "\n",
    "# Save the plot to a PDF file\n",
    "pdf_file_path = 'logplot/gnn_logplot.png'\n",
    "plt.savefig(pdf_file_path, format='png')  # Save as PDF\n",
    "\n",
    "# Show the plot\n",
    "#plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcaa9dc-3c81-4223-8159-79230990354f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn-env",
   "language": "python",
   "name": "gnn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
